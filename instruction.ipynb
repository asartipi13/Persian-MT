{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "gzs = './data/*/*.csv'\n",
    "paths = glob.glob(gzs)\n",
    "\n",
    "# dirs= ['gz', 'zip']\n",
    "# csvs = './csvs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gzs = './data/*/*_*.csv'\n",
    "# paths = glob.glob(gzs)\n",
    "\n",
    "# # dirs= ['gz', 'zip']\n",
    "# # csvs = './csvs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# for p in paths:\n",
    "#     df = pd.read_csv(p)\n",
    "#     langs = df.columns\n",
    "#     lang_other = langs[1] if langs[0]==\"fa\" else langs[0]\n",
    "\n",
    "#     df.rename(columns={lang_other:p.split('-')[-1][:-4]}, inplace=True)\n",
    "#     # print(df.columns)\n",
    "#     df.to_csv(p, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data\\\\Mizan\\\\fa-en.csv',\n",
       " './data\\\\OpenSubtitles\\\\af-fa.csv',\n",
       " './data\\\\OpenSubtitles\\\\bg-fa.csv',\n",
       " './data\\\\OpenSubtitles\\\\bn-fa.csv',\n",
       " './data\\\\OpenSubtitles\\\\br-fa.csv',\n",
       " './data\\\\OpenSubtitles\\\\bs-fa.csv',\n",
       " './data\\\\OpenSubtitles\\\\ca-fa.csv',\n",
       " './data\\\\OpenSubtitles\\\\cs-fa.csv',\n",
       " './data\\\\OpenSubtitles\\\\da-fa.csv',\n",
       " './data\\\\OpenSubtitles\\\\de-fa.csv',\n",
       " './data\\\\OpenSubtitles\\\\el-fa.csv',\n",
       " './data\\\\OpenSubtitles\\\\en-fa.csv',\n",
       " './data\\\\OpenSubtitles\\\\eo-fa.csv',\n",
       " './data\\\\OpenSubtitles\\\\es-fa.csv',\n",
       " './data\\\\OpenSubtitles\\\\et-fa.csv',\n",
       " './data\\\\OpenSubtitles\\\\eu-fa.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-fi.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-fr.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-gl.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-he.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-hi.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-hr.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-hu.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-id.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-is.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-it.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-ja.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-ka.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-kk.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-ko.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-lt.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-lv.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-mk.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-ml.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-ms.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-nl.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-no.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-pl.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-pt.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-pt_br.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-ro.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-ru.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-si.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-sk.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-sl.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-sq.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-sr.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-sv.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-ta.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-te.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-th.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-tl.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-tr.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-uk.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-ur.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-vi.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-ze_en.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-ze_zh.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-zh_cn.csv',\n",
       " './data\\\\OpenSubtitles\\\\fa-zh_tw.csv',\n",
       " './data\\\\PEPC_Bidirectional\\\\en-fa.csv',\n",
       " './data\\\\PEPC_Onedirectional\\\\en-fa.csv',\n",
       " './data\\\\TEP\\\\en-fa.csv',\n",
       " './data\\\\TEP++\\\\en-fa.csv']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fa_tokenize(s): \n",
    "    tokens = s.split()\n",
    "    # tokens_en = s['en'].split()\n",
    "    # len_en = len(tokens_en)\n",
    "    return pd.Series([tokens],index=['tokens'])\n",
    "    \n",
    "def get_fa_tokens_count(df, lang):\n",
    "    all_tokens = []\n",
    "    for row in df['tokens_{}'.format(lang)].values:\n",
    "        all_tokens.extend(row)\n",
    "    unique_tokens = Counter(all_tokens)\n",
    "    return  [len(all_tokens), len(unique_tokens.keys())]\n",
    "\n",
    "def get_all_info(df):\n",
    "    cols = df.columns\n",
    "    info = {}\n",
    "    for lang in cols:\n",
    "        if lang == 'en':\n",
    "            df['tokens_{}'.format(lang)] = df[lang].apply(lambda x: fa_tokenize(x))\n",
    "            info[lang] = get_fa_tokens_count(df, lang)\n",
    "        elif lang == 'fa':\n",
    "            df['tokens_{}'.format(lang)] = df[lang].apply(lambda x: fa_tokenize(x))\n",
    "            info[lang] = get_fa_tokens_count(df, lang)\n",
    "        else:\n",
    "            info[lang] = [0,0]\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['en', 'fa', 'tokens_en', 'tokens_fa'], dtype='object')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data\\\\Mizan\\\\fa-en.csv',\n",
       " './data\\\\PEPC_Bidirectional\\\\en-fa.csv',\n",
       " './data\\\\PEPC_Onedirectional\\\\en-fa.csv',\n",
       " './data\\\\TEP\\\\en-fa.csv',\n",
       " './data\\\\TEP++\\\\en-fa.csv']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paths = ['./data\\\\TEP++\\\\en-fa.csv']\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "df_result = pd.DataFrame({})\n",
    "for p in paths:\n",
    "    df = pd.read_csv(p)[:50]\n",
    "    langs = p.split('\\\\')[-1][:-4].split('-')\n",
    "    lang_fa = 'fa'\n",
    "    lang_other = langs[1] if langs[0]==\"fa\" else langs[0]\n",
    "    \n",
    "    info = get_all_info(df)\n",
    "\n",
    "    dataset = p.split('\\\\')[1] + ' | ' + lang_fa + '-' + lang_other\n",
    "    \n",
    "    df_result = df_result.append({\n",
    "        'dataset': dataset,\n",
    "        'parallel pairs': int(len(df)),\n",
    "        'tokens source': info[lang_fa][0],\n",
    "        'unique tokens source': info[lang_fa][1],\n",
    "        'tokens target': info[lang_other][0],\n",
    "        'unique tokens target':info[lang_other][1],\n",
    "    }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pt_br'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>parallel pairs</th>\n",
       "      <th>tokens source</th>\n",
       "      <th>unique tokens source</th>\n",
       "      <th>tokens target</th>\n",
       "      <th>unique tokens target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mizan | fa-en</td>\n",
       "      <td>50.0</td>\n",
       "      <td>834.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>675.0</td>\n",
       "      <td>383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OpenSubtitles | fa-af</td>\n",
       "      <td>50.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OpenSubtitles | fa-bg</td>\n",
       "      <td>50.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OpenSubtitles | fa-bn</td>\n",
       "      <td>50.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OpenSubtitles | fa-br</td>\n",
       "      <td>50.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>OpenSubtitles | fa-zh_cn</td>\n",
       "      <td>50.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>OpenSubtitles | fa-zh_tw</td>\n",
       "      <td>50.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>PEPC_Bidirectional | fa-en</td>\n",
       "      <td>50.0</td>\n",
       "      <td>618.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>405.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>PEPC_Onedirectional | fa-en</td>\n",
       "      <td>50.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>443.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>TEP | fa-en</td>\n",
       "      <td>50.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>202.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        dataset  parallel pairs  tokens source  \\\n",
       "0                 Mizan | fa-en            50.0          834.0   \n",
       "1         OpenSubtitles | fa-af            50.0          364.0   \n",
       "2         OpenSubtitles | fa-bg            50.0          179.0   \n",
       "3         OpenSubtitles | fa-bn            50.0          340.0   \n",
       "4         OpenSubtitles | fa-br            50.0          340.0   \n",
       "..                          ...             ...            ...   \n",
       "58     OpenSubtitles | fa-zh_cn            50.0          279.0   \n",
       "59     OpenSubtitles | fa-zh_tw            50.0          279.0   \n",
       "60   PEPC_Bidirectional | fa-en            50.0          618.0   \n",
       "61  PEPC_Onedirectional | fa-en            50.0          632.0   \n",
       "62                  TEP | fa-en            50.0          412.0   \n",
       "\n",
       "    unique tokens source  tokens target  unique tokens target  \n",
       "0                  454.0          675.0                 383.0  \n",
       "1                  233.0            0.0                   0.0  \n",
       "2                  146.0            0.0                   0.0  \n",
       "3                  211.0            0.0                   0.0  \n",
       "4                  233.0            0.0                   0.0  \n",
       "..                   ...            ...                   ...  \n",
       "58                 196.0            0.0                   0.0  \n",
       "59                 196.0            0.0                   0.0  \n",
       "60                 395.0          636.0                 405.0  \n",
       "61                 401.0          650.0                 443.0  \n",
       "62                 229.0          440.0                 202.0  \n",
       "\n",
       "[63 rows x 6 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (g:\\anaconda\\envs\\ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (g:\\anaconda\\envs\\ai\\lib\\site-packages)\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\http\\client.py\", line 459, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\http\\client.py\", line 503, in readinto\n",
      "    n = self.fp.readinto(b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 173, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 203, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 315, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 94, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 472, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 341, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 140, in __bool__\n",
      "    return any(self)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 128, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 32, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 204, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 295, in __init__\n",
      "    super().__init__(\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 227, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 305, in _prepare_distribution\n",
      "    return self._factory.preparer.prepare_linked_requirement(\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 508, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 550, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 239, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 102, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 145, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 144, in iter\n",
      "    for x in it:\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 541, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\contextlib.py\", line 131, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"G:\\Anaconda\\envs\\AI\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n",
      "WARNING: Ignoring invalid distribution -cipy (g:\\anaconda\\envs\\ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (g:\\anaconda\\envs\\ai\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (g:\\anaconda\\envs\\ai\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10828/1040575553.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIntegerType\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Create the Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .config(\"spark.sql.autoBroadcastJoinThreshold\", -1) \\\n",
    "    .config(\"spark.executor.memory\", \"3g\") \\\n",
    "    .appName(\"Homework_2\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "008b0f992822207dc3371086db865f2e3d549e6d0b94b092d243da12ff3366e0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('AI': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
